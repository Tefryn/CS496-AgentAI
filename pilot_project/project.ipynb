{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c193de6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Reset directory\n",
    "%cd /content\n",
    "!rm -rf ragen\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/ZihanWang314/ragen.git\n",
    "%cd ragen\n",
    "\n",
    "# Initialize submodules immediately\n",
    "!git submodule update --init --recursive\n",
    "\n",
    "# Install build dependencies\n",
    "!pip install ninja packaging wheel\n",
    "\n",
    "# Install PyTorch 2.5.1\n",
    "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
    "\n",
    "# Install Flash Attention via pre-built wheel (v2.7.0.post2 for Torch 2.5 + Cu12)\n",
    "!pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.0.post2/flash_attn-2.7.0.post2+cu12torch2.5cxx11abiFALSE-cp312-cp312-linux_x86_64.whl\n",
    "\n",
    "# Relax flash-attn requirement in the codebase to accept the installed version\n",
    "!sed -i 's/flash-attn==2.7.4.post1/flash-attn>=2.7.0/g' requirements.txt\n",
    "!sed -i 's/flash-attn==2.7.4.post1/flash-attn>=2.7.0/g' setup.py\n",
    "\n",
    "# Install other dependencies\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Install the package in editable mode\n",
    "!pip install -e .\n",
    "\n",
    "# Install verl submodule\n",
    "%cd verl\n",
    "!pip install -e .\n",
    "%cd .."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
